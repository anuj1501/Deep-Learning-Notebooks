{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DQN_cartpole_game.ipynb","provenance":[],"authorship_tag":"ABX9TyOmQyfvQAzY7Fcu5ME0L7wk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gR9gcY924slX","executionInfo":{"status":"ok","timestamp":1604342051098,"user_tz":-330,"elapsed":2334,"user":{"displayName":"Anuj Raghani","photoUrl":"","userId":"06136699931339747993"}}},"source":["import random\n","import gym\n","import numpy as np\n","from collections import deque\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import Adam\n","import os"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"-LJPRkoF6MHB","executionInfo":{"status":"ok","timestamp":1604342054111,"user_tz":-330,"elapsed":1181,"user":{"displayName":"Anuj Raghani","photoUrl":"","userId":"06136699931339747993"}}},"source":["env = gym.make('CartPole-v0')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5ehHoxj-6QH","executionInfo":{"status":"ok","timestamp":1604342056247,"user_tz":-330,"elapsed":1076,"user":{"displayName":"Anuj Raghani","photoUrl":"","userId":"06136699931339747993"}},"outputId":"d779af52-2736-4435-c535-4ad573e2d91d","colab":{"base_uri":"https://localhost:8080/"}},"source":["state_size = env.observation_space.shape[0]\n","\n","state_size"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"qal3MsY9_BwP","executionInfo":{"status":"ok","timestamp":1604342058127,"user_tz":-330,"elapsed":1105,"user":{"displayName":"Anuj Raghani","photoUrl":"","userId":"06136699931339747993"}},"outputId":"f383625f-8b10-41c2-8b8e-adc663f71261","colab":{"base_uri":"https://localhost:8080/"}},"source":["action_size = env.action_space.n\n","action_size"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"ox8vw4Dr_LtX","executionInfo":{"status":"ok","timestamp":1604342060028,"user_tz":-330,"elapsed":1067,"user":{"displayName":"Anuj Raghani","photoUrl":"","userId":"06136699931339747993"}}},"source":["batch_size = 32\n","\n","n_episodes = 1000\n","\n","output_dir = 'model_output/cartpole/'\n","\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"zgK8KUTVC-WJ","executionInfo":{"status":"ok","timestamp":1604342067977,"user_tz":-330,"elapsed":1107,"user":{"displayName":"Anuj Raghani","photoUrl":"","userId":"06136699931339747993"}}},"source":["class DQNAgent:\n","    \n","    def __init__(self, state_size, action_size):\n","        self.state_size = state_size\n","        self.action_size = action_size\n","        \n","        self.memory = deque(maxlen=2000) \n","        \n","        self.gamma = 0.95\n","        \n","        self.epsilon = 1.0\n","        \n","        self.epsilon_decay = 0.995\n","        \n","        self.epsilon_min = 0.01\n","        \n","        self.learning_rate = 0.001\n","        \n","        self.model = self._build_model()\n","\n","    def _build_model(self):\n","\n","      model = Sequential()\n","\n","      model.add(Dense(24,input_dim = self.state_size, activation='relu'))\n","\n","      model.add(Dense(24, activation='relu'))\n","\n","      model.add(Dense(self.action_size, activation='linear'))\n","\n","      model.compile(loss='mse', optimizer = Adam(lr = self.learning_rate))\n","\n","    def remember(self,state, action, reward, next_state, done):\n","\n","      self.memory.append((state, action, reward, next_state, done))\n","\n","    def act(self, state):\n","\n","      if np.random.rand() <= self.epsilon:\n","\n","        return random.randrange(self.action_size)\n","      \n","      act_values = self.model.predict(state)\n","\n","      return np.argmax(act_values)\n","    def replay(self, batch_size): \n","        \n","      minibatch = random.sample(self.memory, batch_size) \n","        \n","      for state, action, reward, next_state, done in minibatch: \n","        \n","        target = reward # N.B.: if done\n","        \n","        if not done: \n","          \n","          target = (reward + self.gamma * np.amax(self.model.predict(next_state)[0])) # (maximum target Q based on future action a')\n","        \n","        target_f = self.model.predict(state) \n","        \n","        target_f[0][action] = target\n","            \n","        self.model.fit(state, target_f, epochs=1, verbose=0)\n","\n","        if self.epsilon > self.epsilon_min:\n","          \n","          self.epsilon *= self.epsilon_decay\n","\n","    \n","\n","    def load(self, name):\n","        self.model.load_weights(name)\n","\n","    def save(self, name):\n","        self.model.save_weights(name)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"p43wzbomKK0r","executionInfo":{"status":"ok","timestamp":1604342069275,"user_tz":-330,"elapsed":682,"user":{"displayName":"Anuj Raghani","photoUrl":"","userId":"06136699931339747993"}}},"source":["agent = DQNAgent(state_size, action_size)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMUMQ1x8KfFF","executionInfo":{"status":"error","timestamp":1604342071443,"user_tz":-330,"elapsed":946,"user":{"displayName":"Anuj Raghani","photoUrl":"","userId":"06136699931339747993"}},"outputId":"a58f5485-465c-4162-af86-9b026b8240fa","colab":{"base_uri":"https://localhost:8080/","height":384}},"source":["done = False\n","\n","for e in range(n_episodes): \n","\n","    state = env.reset() \n","    state = np.reshape(state, [1, state_size])\n","    \n","    for time in range(5000):  \n","        \n","        #  env.render()\n","\n","        action = agent.act(state) \n","    \n","        next_state, reward, done, _ = env.step(action) \n","        \n","        reward = reward if not done else -10 \n","        \n","        next_state = np.reshape(next_state, [1, state_size])\n","        \n","        agent.remember(state, action, reward, next_state, done) \n","\n","        state = next_state \n","        \n","        if done: \n","            print(\"episode: {}/{}, score: {}, e: {:.2}\".format(e, n_episodes, time, agent.epsilon))\n","            break \n","\n","    if len(agent.memory) > batch_size:\n","        agent.replay(batch_size)\n","\n","    #if e % 50 == 0:\n","        #agent.save(output_dir + \"weights_\" + '{:04d}'.format(e) + \".hdf5\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["episode: 0/1000, score: 22, e: 1.0\n","episode: 1/1000, score: 12, e: 1.0\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-36255865db35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#if e % 50 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-ca3c45a42cc5>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m           \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (maximum target Q based on future action a')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtarget_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"]}]},{"cell_type":"code","metadata":{"id":"N0qs02PwPTxh"},"source":[""],"execution_count":null,"outputs":[]}]}